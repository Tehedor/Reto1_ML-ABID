{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las librerias fueron correctamente importadas.\n"
     ]
    }
   ],
   "source": [
    "# General import and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Estimators\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, roc_curve, roc_auc_score\n",
    "\n",
    "# Optimization\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time optimization\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Variables globales y funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_data(case, X):\n",
    "    \n",
    "    if case in {1, 3, 5}:\n",
    "        prep = StandardScaler().fit(X)\n",
    "        X_scaled = prep.transform(X)\n",
    "        \n",
    "    elif case in {2, 4, 6}:\n",
    "        prep = ColumnTransformer([\n",
    "            ('numericas', StandardScaler(), numeric_vars)\n",
    "        ], remainder='passthrough').fit(X) \n",
    "        X_scaled = prep.transform(X) \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"El valor de 'case' no es válido. Debe estar entre 1 y 6.\")\n",
    "    \n",
    "    return X_scaled, prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(case, X, y, strategy_under, strategy_over, neighbors=5):\n",
    "    \n",
    "    if case in {1, 2}:\n",
    "        ovsamp = SMOTE(sampling_strategy=strategy_over, k_neighbors=neighbors, random_state=seed)\n",
    "        X_resampled, y_resampled = ovsamp.fit_resample(X, y)\n",
    "        \n",
    "    elif case in {3, 4}:\n",
    "        unsamp = RandomUnderSampler(sampling_strategy=strategy_under, random_state=seed)\n",
    "        X_resampled, y_resampled = unsamp.fit_resample(X, y)\n",
    "        \n",
    "    elif case in {5, 6}:\n",
    "        unsamp = RandomUnderSampler(sampling_strategy=strategy_under, random_state=seed)\n",
    "        X_undersampled, y_undersampled = unsamp.fit_resample(X, y)\n",
    "        ovsamp = SMOTE(sampling_strategy=strategy_over, k_neighbors=neighbors, random_state=seed)\n",
    "        X_resampled, y_resampled = ovsamp.fit_resample(X_undersampled, y_undersampled)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"El valor de 'case' no es válido. Debe estar entre 1 y 6.\")\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Carga del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados correctamente\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"formated/train_exportado.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "url = \"formated/test_exportado.csv\"\n",
    "df_test = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Seleccion de las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    # Caracteristicas numericas\n",
    "    'ApprovalFY', 'NoEmp', 'DisbursementGross',\n",
    "\n",
    "    # Caracteristicas categoricas binarias\n",
    "    'NewExist_Binary', 'Franchise_Binary', 'UrbanRural_Binary',\n",
    "    'RevLineCr_Binary', 'LowDoc_Binary', 'CreateJob_Binary',\n",
    "    'RetainedJob_Binary',\n",
    "    \n",
    "    # Características temporales\n",
    "    'ApprovalDate_quarter', 'DisbursementDate_quarter', \n",
    "\n",
    "    # Características relacionadas con Bank tras un One Hot Encoding\n",
    "    'Bank_CAPITAL ONE NATL ASSOC', 'Bank_CITIZENS BANK NATL ASSOC',\n",
    "    'Bank_COMMUNITY CAP. DEVEL CORP', 'Bank_FIFTH THIRD BANK',\n",
    "    'Bank_FIRSTMERIT BANK, N.A.', 'Bank_HAMILTON CNTY DEVEL COMPANY IN',\n",
    "    'Bank_JPMORGAN CHASE BANK NATL ASSOC',\n",
    "    'Bank_KEYBANK NATIONAL ASSOCIATION', 'Bank_Otros',\n",
    "    'Bank_PNC BANK, NATIONAL ASSOCIATION',\n",
    "    'Bank_THE HUNTINGTON NATIONAL BANK',\n",
    "    'Bank_U.S. BANK NATIONAL ASSOCIATION',\n",
    "    'Bank_WELLS FARGO BANK NATL ASSOC',\n",
    "\n",
    "    # Características relacionadas con BankState tras un One Hot Encoding\n",
    "    'BankState_CA', 'BankState_DE', 'BankState_IL', 'BankState_IN',\n",
    "    'BankState_OH', 'BankState_Otros', 'BankState_RI', \n",
    "    'BankState_SD', 'BankState_VA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = ['ApprovalFY', 'NoEmp', 'DisbursementGross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Carga de los datos y division en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[selected_features] \n",
    "y = df['Accept'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Clasificador Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.1 Seleccion del caso de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case - caso de preprocesado seleccionado, valores posibles: 1, 2, 3, 4, 5, 6\n",
    "case = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if case in {1, 2}:\n",
    "    strategy_under = 0\n",
    "    strategy_over = 1\n",
    "    neighbors = 5\n",
    "    \n",
    "elif case in {3, 4}:\n",
    "    strategy_under = 0.8\n",
    "    strategy_over = 0\n",
    "    neighbors = 0\n",
    "    \n",
    "elif case in {5, 6}:\n",
    "    strategy_under = 0.25\n",
    "    strategy_over = 0.5\n",
    "    neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, prep = standard_data(case, X_train)\n",
    "X_resampled, y_resampled = resample_data(case, X_scaled, y_train, strategy_under, strategy_over, neighbors)\n",
    "X_pca = X_resampled\n",
    "\n",
    "X_test_scaled = prep.transform(X_test)\n",
    "X_test_pca = X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.7 Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "optm_Forest = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 250, 300],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [25, 35],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': [\"sqrt\", 8, 10],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(optm_Forest, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=3, n_jobs=-1)\n",
    "\n",
    "inicio = time.time()\n",
    "grid_search.fit(X_pca, y_resampled)\n",
    "fin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo_total = (fin - inicio) / 60\n",
    "print(f\"La celda tardó {tiempo_total} minutos en ejecutarse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Mejores parámetros: \", grid_search.best_params_)\n",
    "print(\"Mejor score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_models = results_df.nlargest(10, \"mean_test_score\")\n",
    "\n",
    "print(\"\\nLos 10 mejores modelos:\")\n",
    "for index, row in top_10_models.iterrows():\n",
    "    print(\"\\nModelo:\")\n",
    "    print(f\"Parámetros: {row['params']}\")\n",
    "    print(f\"Puntuación media de prueba: {row['mean_test_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6.3 Clasificador MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.3.1 Seleccion del caso de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case - caso de preprocesado seleccionado, valores posibles: 1, 2, 3, 4, 5, 6\n",
    "case = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "if case in {1, 2}:\n",
    "    strategy_under = 0\n",
    "    strategy_over = 1\n",
    "    neighbors = 5\n",
    "    \n",
    "elif case in {3, 4}:\n",
    "    strategy_under = 0.8\n",
    "    strategy_over = 0\n",
    "    neighbors = 0\n",
    "    \n",
    "elif case in {5, 6}:\n",
    "    strategy_under = 0.25\n",
    "    strategy_over = 0.5\n",
    "    neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, prep = standard_data(case, X_train)\n",
    "X_resampled, y_resampled = resample_data(case, X_scaled, y_train, strategy_under, strategy_over, neighbors)\n",
    "X_pca = X_resampled\n",
    "\n",
    "X_test_scaled = prep.transform(X_test)\n",
    "X_test_pca = X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.3.7 Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_total = np.concatenate([X_pca, X_test_pca])\n",
    "y_total = np.concatenate([y_resampled, y_test])\n",
    "\n",
    "fold = np.array([-1] * len(X_sel) + [0] * len(X_test_pca))\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "\n",
    "optm_Mlp = MLPClassifier(max_iter=1000, early_stopping=True, validation_fraction=0.15, random_state=seed)\n",
    "                         \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(32, 64, 32), (64, 128, 64), (100, 50, 25), (64, 128, 64, 32)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [200, 400, 600, 'auto']\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(optm_Mlp, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=ps, n_jobs=-1)\n",
    "\n",
    "inicio = time.time()\n",
    "grid_search.fit(X_total, y_total)\n",
    "fin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo_total = (fin - inicio) / 60\n",
    "print(f\"La celda tardó {tiempo_total} minutos en ejecutarse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Mejores parámetros: \", grid_search.best_params_)\n",
    "print(\"Mejor score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_models = results_df.nlargest(10, \"mean_test_score\")\n",
    "\n",
    "print(\"\\nLos 10 mejores modelos:\")\n",
    "for index, row in top_10_models.iterrows():\n",
    "    print(\"\\nModelo:\")\n",
    "    print(f\"Parámetros: {row['params']}\")\n",
    "    print(f\"Puntuación media de prueba: {row['mean_test_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Clasificador GBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Seleccion del caso de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case - caso de preprocesado seleccionado, valores posibles: 1, 2, 3, 4, 5, 6\n",
    "case = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "if case in {1, 2}:\n",
    "    strategy_under = 0\n",
    "    strategy_over = 1\n",
    "    neighbors = 5\n",
    "    \n",
    "elif case in {3, 4}:\n",
    "    strategy_under = 0.8\n",
    "    strategy_over = 0\n",
    "    neighbors = 0\n",
    "    \n",
    "elif case in {5, 6}:\n",
    "    strategy_under = 0.25\n",
    "    strategy_over = 0.5\n",
    "    neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, prep = standard_data(case, X_train)\n",
    "X_resampled, y_resampled = resample_data(case, X_scaled, y_train, strategy_under, strategy_over, neighbors)\n",
    "X_pca = X_resampled\n",
    "\n",
    "X_test_scaled = prep.transform(X_test)\n",
    "X_test_pca = X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo básico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_GBC = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.7 Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "optm_GBC = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     \n",
    "    'learning_rate': [0.01, 0.05, 0.1], \n",
    "    'max_depth': [3, 5],        \n",
    "    'min_samples_split': [2, 5],    \n",
    "    'min_samples_leaf': [2, 4],  \n",
    "    'subsample': [0.8, 1.0],            \n",
    "    'max_features': ['sqrt', 8],     \n",
    "    'criterion' : ['friedman_mse', 'squared_error'],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(optm_GBC , param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=3, n_jobs=-1)\n",
    "\n",
    "inicio = time.time()\n",
    "grid_search.fit(X_pca, y_resampled)\n",
    "fin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo_total = (fin - inicio) / 60\n",
    "print(f\"La celda tardó {tiempo_total} minutos en ejecutarse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Mejores parámetros: \", grid_search.best_params_)\n",
    "print(\"Mejor score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_models = results_df.nlargest(10, \"mean_test_score\")\n",
    "\n",
    "print(\"\\nLos 10 mejores modelos:\")\n",
    "for index, row in top_10_models.iterrows():\n",
    "    print(\"\\nModelo:\")\n",
    "    print(f\"Parámetros: {row['params']}\")\n",
    "    print(f\"Puntuación media de prueba: {row['mean_test_score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

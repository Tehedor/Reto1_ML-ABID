{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"width:100%;position:relative\">\n",
    "  <div style=\"width:80%;float:right;\">\n",
    "    <h1>Challenge Loan Approval Prediction in Pennsylvania</h1>\n",
    "    <h3>Entrenamiento y evaluación de los modelos</h3>\n",
    "    <h5>Grupo 2</h5>\n",
    "  </div>\n",
    "        <img style=\"width:15%;\" src=\"./images/logo.jpg\" alt=\"UPM\" />\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Importar librerias](#1.-Importar-librerias)\n",
    "2. [Variables globales y funciones auxiliares](#2.-Variables-globales-y-funciones-auxiliares)\n",
    "3. [Carga del dataframe](#3.-Carga-del-dataframe)\n",
    "4. [Selección de las características](#4.-Seleccion-de-las-caracteristicas)\n",
    "5. [Carga de los datos y división en entrenamiento y test](#5.-Carga-de-los-datos-y-division-en-entrenamiento-y-test)\n",
    "6. [Modelos seleccionados](#6.-Modelos-seleccionados)\n",
    "    * 6.1 [Introducción](#6.1-Introduccion)\n",
    "    * 6.2 [Clasificador Random Forest](#6.2-Clasificador-Random-Forest)\n",
    "    * 6.3 [Clasificador MLP](#6.3-Clasificador-MLP)\n",
    "7. [Exportar CSV](#7.-Exportar-CSV)\n",
    "    * 7.1 [Clasificador Random Forest](#7.1-Clasificador-Random-Forest)\n",
    "    * 7.2 [Clasificador MLP](#7.2-Clasificador-MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las librerias fueron correctamente importadas.\n"
     ]
    }
   ],
   "source": [
    "# General import and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Estimators\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "# Optimization\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time optimization\n",
    "import time\n",
    "\n",
    "print(\"Todas las librerias fueron correctamente importadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Variables globales y funciones auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se fija un seed para todo el documento para fijar la aleatoriedad y así obtener resultados replicables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función utilizado para evaluar los distintos umbrales en la curva de ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Recall:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función utilizada para estandarizar los datos en función del caso de preprocesado escogido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_data(case, X):\n",
    "    \n",
    "    if case in {1, 3, 5}:\n",
    "        prep = StandardScaler().fit(X)\n",
    "        X_scaled = prep.transform(X)\n",
    "        \n",
    "    elif case in {2, 4, 6}:\n",
    "        prep = ColumnTransformer([\n",
    "            ('numericas', StandardScaler(), numeric_vars)\n",
    "        ], remainder='passthrough').fit(X) \n",
    "        X_scaled = prep.transform(X) \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"El valor de 'case' no es válido. Debe estar entre 1 y 6.\")\n",
    "    \n",
    "    return X_scaled, prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función utilizada para muestrear los datos en función del caso de preprocesado escogido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(case, X, y, strategy_under, strategy_over, neighbors=5):\n",
    "    \n",
    "    if case in {1, 2}:\n",
    "        ovsamp = SMOTE(sampling_strategy=strategy_over, k_neighbors=neighbors, random_state=seed)\n",
    "        X_resampled, y_resampled = ovsamp.fit_resample(X, y)\n",
    "        \n",
    "    elif case in {3, 4}:\n",
    "        unsamp = RandomUnderSampler(sampling_strategy=strategy_under, random_state=seed)\n",
    "        X_resampled, y_resampled = unsamp.fit_resample(X, y)\n",
    "        \n",
    "    elif case in {5, 6}:\n",
    "        unsamp = RandomUnderSampler(sampling_strategy=strategy_under, random_state=seed)\n",
    "        X_undersampled, y_undersampled = unsamp.fit_resample(X, y)\n",
    "        ovsamp = SMOTE(sampling_strategy=strategy_over, k_neighbors=neighbors, random_state=seed)\n",
    "        X_resampled, y_resampled = ovsamp.fit_resample(X_undersampled, y_undersampled)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"El valor de 'case' no es válido. Debe estar entre 1 y 6.\")\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Carga del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos de la ruta *formated/train_exportado.csv*, los cuales son los datos ya procesados por uno de nuestros compañeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados correctamente\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"formated/train_exportado.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Datos cargados correctamente\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También cargamos el test que debemos predecir para Kaggle de la ruta *formated/test_exportado.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cargado correctamente\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"formated/test_exportado.csv\"\n",
    "df_test = pd.read_csv(url)\n",
    "\n",
    "print(\"Test cargado correctamente\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Seleccion de las caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionan todas las características a excepción de las categoricas sin codificadar, al ya tener la misma információn codificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    # Caracteristicas numericas\n",
    "    'ApprovalFY', 'NoEmp', 'CreateJob', 'RetainedJob', 'DisbursementGross',\n",
    "\n",
    "    # Caracteristicas categoricas binarias\n",
    "    'NewExist_Binary', 'Franchise_Binary', 'UrbanRural_Binary',\n",
    "    'RevLineCr_Binary', 'LowDoc_Binary', 'CreateJob_Binary',\n",
    "    'RetainedJob_Binary',\n",
    "\n",
    "    # Caracteristicas categoricas codificadas\n",
    "    'Bank_Categorized_cod', 'BankState_Categorized_cod',\n",
    "    'ApprovalFY_Grouped_cod', 'NoEmp_Grouped_cod', \n",
    "    'DisbursementGross_Grouped_cod',\n",
    "\n",
    "     # Time-related features\n",
    "    'ApprovalDate_quarter', 'DisbursementDate_quarter',\n",
    "\n",
    "    # Caracteristicas relacionadas con BankState_Categorized tras un One Hot Encoding\n",
    "    'BankState_DE', 'BankState_IL', 'BankState_OH', \n",
    "    'BankState_Otros', 'BankState_RI'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las cuales, numéricas son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = ['ApprovalFY', 'NoEmp', 'CreateJob', 'RetainedJob', 'DisbursementGross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5. Carga de los datos y division en entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las caracteristicas seleccionadas en la variable X y el objetivo *Accept* en la variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[selected_features] \n",
    "y = df['Accept'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separa ya en entrenamiento y test para no falsear los datos del test al realizar el balanceo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de subir el modelo a Kaggle, ya se nos da dividido el entrenamiento y el test. Por ello, se utilizarán todos los datos tratados como entrenamiento (aunque también se le aplicará el mejor caso de preprocesado para cada modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X\n",
    "y_train_final = y\n",
    "\n",
    "X_test_final = df_test[selected_features] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelos seleccionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6.1 Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el anterior notebook se evaluaron 10 modelos tanto por F1 score como por ROC-AUC score. Los resultados de mayor a menor de los modelos respecto a la F1-Score fueron los siguientes:\n",
    "* Random Forest: 0.867449\n",
    "* MLP: 0.811513\n",
    "* DecisionTree: 0.790538\n",
    "* KNN: 0.767966\n",
    "* LinearSVC: 0.664541\n",
    "* LogReg: 0.663316\n",
    "* SVC_sigmoid: 0.617281\n",
    "* GaussianNB: 0.568654\n",
    "* SVC_poly: 0.526099\n",
    "* SVC_rbf: 0.411304\n",
    "\n",
    "En cambio, los resultados de mayor a menor de los modelos respecto a la ROC-AUC Score fueron los siguientes:\n",
    "* Random Forest: 0.934825\n",
    "* MLP: 0.884770\n",
    "* KNN: 0.874725\n",
    "* DecisionTree: 0.795805\n",
    "* LinearSVC: 0.715244\n",
    "* LogReg: 0.715162\n",
    "* GaussianNB: 0.705878\n",
    "* SVC_rbf: 0.692410\n",
    "* SVC_poly: 0.658396\n",
    "* SVC_sigmoid: 0.556961"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decidió entrenar y optimizar los hiperparámetros de cuatro modelos. Los modelos escogidos fueron Random Forest, MLP, KNN y LinearSVC, es decir, los cuatro primeros tanto por F1-score como por ROC-AUC score (se ha excluido Decision Tree por ya estar probando un clasificador basado en árbol de decisión, y en un principio mejor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6.2 Clasificador LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.1 Seleccion del caso de preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccion del caso de preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case - caso de preprocesado seleccionado, valores posibles: 1, 2, 3, 4, 5, 6\n",
    "case = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros base para cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if case in {1, 2}:\n",
    "    strategy_under = 0\n",
    "    strategy_over = 1\n",
    "    neighbors = 5\n",
    "    \n",
    "elif case in {3, 4}:\n",
    "    strategy_under = 0.8\n",
    "    strategy_over = 0\n",
    "    neighbors = 0\n",
    "    \n",
    "elif case in {5, 6}:\n",
    "    strategy_under = 0.25\n",
    "    strategy_over = 0.5\n",
    "    neighbors = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estandarizan los datos en función del caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, prep = standard_data(case, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestrean los datos en función del caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = resample_data(case, X_scaled, y_train, strategy_under, strategy_over, neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reducen las dimensionalidades mediante un *PCA*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_pca_full = pca.fit_transform(X_resampled)\n",
    "\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_comp = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
    "X_pca = X_pca_full[:, :n_comp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que se ha realizado distintos preprocesados al entrenamiento, hay que realizarlos al conjunto de test para obtener resultados coherentes.\n",
    "\n",
    "No es necesario realizar las tecnicas de muestreo ya que eso son técnicas para balancear nuestro conjunto de entrenamiento. Solamente es necesario realizar la misma estandarización de las características y aplicar la misma reducción de dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = prep.transform(X_test)\n",
    "X_test_pca_full = pca.transform(X_test_scaled)\n",
    "X_test_pca = X_test_pca_full[:, :n_comp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.2 Definicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo básico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVC = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.3 Entrenamiento y evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo y comprobamos su exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVC.fit(X_pca, y_resampled)\n",
    "\n",
    "predicted_SVC = model_SVC.predict(X_test_pca)\n",
    "expected_SVC = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7204872646733111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(expected_SVC, predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.4 Null accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se va a evaluar si  el modelo siempre predice la clase más frecuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3765\n",
       "0     750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_y_test = pd.Series(y_test)\n",
    "s_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8338870431893688"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1661129568106312"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - y_test.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8338870431893688"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.833887\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra exactitud es de 7204, la cual es peor que la *null accuracy*, es decir, ahora mismo no tenemos un buen modelo ya que se predecirían un mayor número de resultados en el caso de siempre predecir la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.5 Matriz de confusion y F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la matriz de confusión y el informe de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 410  340]\n",
      " [ 922 2843]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(expected_SVC, predicted_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.55      0.39       750\n",
      "           1       0.89      0.76      0.82      3765\n",
      "\n",
      "    accuracy                           0.72      4515\n",
      "   macro avg       0.60      0.65      0.61      4515\n",
      "weighted avg       0.80      0.72      0.75      4515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(expected_SVC, predicted_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa lo que hemos estado comentando durante todo el documento, tenemos un f1-score del 0.82 para los 1s mientras que estamos obteniendo un 0.39 para los 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.7 - Optimizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de nada, observamos cuales son los parámetros de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': 'auto',\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVC.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora seleccionamos los parametros a evaluar mediante un GridSearchCV. Como se evalua mediante un *cross validation*, siempre escogeremos los casos 3 o 4 de preprocesado para falsear menos los datos.\n",
    "\n",
    "Estos son los parámetros:\n",
    "\n",
    "C: Controla la regularización; valores altos reducen el margen de error pero pueden causar sobreajuste.\n",
    "\n",
    "loss: Función de pérdida utilizada.\n",
    "\n",
    "penalty: Tipo de regularización aplicada.\n",
    "\n",
    "max_iter: Número máximo de iteraciones para la convergencia del algoritmo.\n",
    "\n",
    "tol: Tolerancia para la optimización.\n",
    "\n",
    "multi_class: Estrategia para clasificación multiclase."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "# Definir los hiperparámetros a probar para LinearSVC\n",
    "#param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "    'penalty': ['l2'],  # Regularización L2 (si usas \"l1\" puede ser poco estable para LinearSVC)\n",
    "    'loss': ['squared_hinge'],  # Tipo de pérdida\n",
    "    'dual': [True, False],  # Dualidad en la formulación del problema\n",
    "    'tol': [1e-4, 1e-3, 1e-2],  # Tolerancia para la optimización\n",
    "    'max_iter': [1000, 2000, 3000],  # Número máximo de iteraciones\n",
    "    'intercept_scaling': [0.1, 1, 10],  # Ajuste de la escala del término de intersección\n",
    "    'class_weight': [None, 'balanced'],  # Ajuste de los pesos de las clases (útil para clases desbalanceadas)\n",
    "    'random_state': [42]  # Establecer una semilla para la aleatoriedad\n",
    "}\n",
    "\n",
    "# Definir los métodos de evaluación con average='weighted'\n",
    "#scorers = {\n",
    "    'f1': make_scorer(f1_score, average='weighted'),\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'recall': make_scorer(recall_score, average='weighted', zero_division=0)\n",
    "}\n",
    "\n",
    "# Aplicar GridSearchCV con LinearSVC\n",
    "#grid_search_SVC = GridSearchCV(\n",
    "    LinearSVC(),\n",
    "    param_grid,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorers,\n",
    "    refit='f1',  # Refitar con la mejor métrica ('f1' en este caso)\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#grid_search_SVC.fit(X_pca, y_resampled)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "#print(\"Mejores parámetros encontrados:\", grid_search_SVC.best_params_)\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "#results = pd.DataFrame(grid_search_SVC.cv_results_)\n",
    "\n",
    "# Ordenar por cada métrica y mostrar los 5 mejores modelos\n",
    "#for metric in ['mean_test_f1', 'mean_test_accuracy', 'mean_test_recall']:\n",
    "    print(f\"\\nTop 5 modelos según {metric}:\")\n",
    "    sorted_results = results.sort_values(by=metric, ascending=False)\n",
    "    \n",
    "    #for mean_score, std_score, params in zip(\n",
    "        sorted_results[metric].head(5),\n",
    "        sorted_results[f\"std_test_{metric.split('_')[-1]}\"].head(5),\n",
    "        sorted_results[\"params\"].head(5)\n",
    "    ):\n",
    "        print(f\"{mean_score:.3f} (+/-{std_score * 2:.3f}) para {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.8 Entramiento y evaluacion con hiperparametros optimizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Definicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los mejores parámetros (no se define con *grid_search.best_params_* para probar varias opciones de forma sencilla)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo desagregando el diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SVC = LinearSVC(\n",
    "    C=0.01,  \n",
    "    class_weight='balanced', \n",
    "    dual=True, \n",
    "    intercept_scaling=1, \n",
    "    loss='squared_hinge',  \n",
    "    max_iter=100000,  \n",
    "    penalty='l2',\n",
    "    random_state=42,  \n",
    "    tol=0.0000001  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Entrenamiento y evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo y comprobamos su exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SVC.fit(X_pca, y_resampled)\n",
    "\n",
    "predicted_For_opt = final_SVC.predict(X_test_pca)\n",
    "expected_For_opt = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6682170542635659"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(expected_For_opt, predicted_For_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Matriz de confusion y F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión y el informe de clasificación también es muy similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 484  266]\n",
      " [1232 2533]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(expected_For_opt, predicted_For_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.65      0.39       750\n",
      "           1       0.90      0.67      0.77      3765\n",
      "\n",
      "    accuracy                           0.67      4515\n",
      "   macro avg       0.59      0.66      0.58      4515\n",
      "weighted avg       0.80      0.67      0.71      4515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(expected_For_opt, predicted_For_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2.9 Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra los resultados de los modelos optimizados y sin optimizar. Cabe recalcar que se probaron otros cuatro conjuntos de hiperparámetros para la mayoria de los casos de preprocesado, pero se acabó considerando absurdo porque mejoraba o empeoraba 0.01 en diversos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 1 : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.28      0.63      0.39       750\n",
    "           1       0.90      0.67      0.77      3765\n",
    "\n",
    "    accuracy                           0.67      4515\n",
    "\n",
    "Caso 2 : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.26      0.68      0.38       750\n",
    "           1       0.91      0.62      0.73      3765\n",
    "\n",
    "    accuracy                           0.63      4515\n",
    "\n",
    "Caso 3 : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.28      0.65      0.39       750\n",
    "           1       0.90      0.67      0.77      3765\n",
    "\n",
    "    accuracy                           0.67      4515\n",
    "\n",
    "Caso 4 : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.26      0.68      0.38       750\n",
    "           1       0.91      0.62      0.73      3765\n",
    "\n",
    "    accuracy                           0.63      4515\n",
    "\n",
    "Caso 5 : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.28      0.64      0.39       750\n",
    "           1       0.90      0.67      0.77      3765\n",
    "\n",
    "    accuracy                           0.67      4515\n",
    "\n",
    "Caso 6 : \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.26      0.69      0.38       750\n",
    "           1       0.91      0.62      0.74      3765\n",
    "\n",
    "    accuracy                           0.63      4515   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoria de los casos dan resultados similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Exportar CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7.1 Clasificador SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 7.1.1 Seleccion del caso de preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccion del caso de preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case - caso de preprocesado seleccionado, valores posibles: 1, 2, 3, 4, 5, 6\n",
    "case = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros base para cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if case in {1, 2}:\n",
    "    strategy_under = 0\n",
    "    strategy_over = 1\n",
    "    neighbors = 5\n",
    "    \n",
    "elif case in {3, 4}:\n",
    "    strategy_under = 0.9\n",
    "    strategy_over = 0\n",
    "    neighbors = 0\n",
    "    \n",
    "elif case in {5, 6}:\n",
    "    strategy_under = 0.25\n",
    "    strategy_over = 0.5\n",
    "    neighbors = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estandarizan los datos en función del caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_final, prep_final = standard_data(case, X_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestrean los datos en función del caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_final, y_resampled_final = resample_data(case, X_scaled_final, y_train_final, strategy_under, strategy_over, neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reducen las dimensionalidades mediante un *PCA*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = PCA()\n",
    "X_pca_full_final = pca_final.fit_transform(X_resampled_final)\n",
    "\n",
    "cumulative_variance_ratio_final = np.cumsum(pca_final.explained_variance_ratio_)\n",
    "n_comp_final = np.argmax(cumulative_variance_ratio_final >= 0.95) + 1\n",
    "X_pca_final = X_pca_full_final[:, :n_comp_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se preprocesa el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_final = prep_final.transform(X_test_final)\n",
    "X_test_pca_full_final = pca_final.transform(X_test_scaled_final)\n",
    "X_test_pca_final = X_test_pca_full_final[:, :n_comp_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 7.1.2 Entrenamiento y exportacion de las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena con los nuevos valores de train y test, y se modifica el umbral de probabilidades. En un principio, el valor del umbral era el de la variable *op_thres_Random*, pero se decidió finalmente que el valor del umbral fueran valores numéricos para que fuera más sencillo hacer diversas pruebas en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SVC.fit(X_pca_final, y_resampled_final)\n",
    "\n",
    "probs_For_opt = final_SVC.predict(X_test_pca_final) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un *dataframe* con las predicciones obtenidas con su correspondiente *id*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accept_KNN = pd.DataFrame(probs_For_opt, columns=['Accept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_test['id'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_KNN = pd.concat([df_id, df_accept_KNN], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos los resultados obtenidos para tener una idea de la proporción de 1s y 0s de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accept\n",
       "0    1808\n",
       "1    1476\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_KNN['Accept'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transforma el *dataframe* a un archivo *CSV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_KNN.to_csv('./svc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
